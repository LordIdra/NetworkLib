# NetworkLib
This is a library designed for training basic neural networks, including dataset handling and importing from .txt files. As of writing this, the library can run a basic fully-connected deep neural network simulation with the ability to add layers and set custom network structure. The algorithm used is backpropagation, however matrices are not used (yet!). I will add more information here as the library grows.

# HOW TO USE/API
WIP - I will write this section once I have more of the library built. For now this serves as a good place to log changes and save code.

# CHANGELOG

`0.0.1`
+ Added functions.py including all external/utility functions needed for the dnn library
+ Added basic dnn library using forward feed/backpropagate for weight adjustments (biases soon)
+ Added 1-1-1 multiplication example for checking the main algorithm is working
+ Added 4 basic activation functions: sigmoid, tanh, linearRELU and leakyRELU
+ Added benchmark for activation functions
